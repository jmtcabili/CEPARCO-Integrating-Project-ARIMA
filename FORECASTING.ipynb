{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NPq5_orwibzb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "###\n",
        "\n",
        "# Read the file\n",
        "#df = pd.read_csv('dataset.txt')  # or 'your_file.txt' if it's CSV-formatted\n",
        "\n",
        "# Extract the 'values' column\n",
        "#values = df['value']  # returns a Series\n",
        "\n",
        "#values.head()\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff = []\n",
        "timing_data = []\n",
        "\n",
        "\n",
        "loop = 20\n",
        "total_time = 0.0\n",
        "ARRAY_SIZE = 1<<26\n",
        "\n",
        "for i in range(0,ARRAY_SIZE):\n",
        "  timing_data.append(i % 5 + 1.0)\n",
        "\n",
        "\n",
        "for n in range(0,loop):\n",
        "\n",
        "\n",
        "  start = time.perf_counter()\n",
        "  for x in range(0,len(timing_data)-1):\n",
        "\n",
        "    diff.append(timing_data[x+1] - timing_data[x])\n",
        "  end = time.perf_counter()\n",
        "  total_time += end-start\n",
        "\n",
        "print(\"Total Time for\",loop,\"loops (Seconds): \",total_time,\"\\n\")\n",
        "print(\"Average Time (Seconds): \",total_time/loop,\"\\n\")\n",
        "\n",
        "for x in range(0,10):\n",
        "  #print(values[x+1],\"\\n\")\n",
        "\n",
        "  print(diff[x],\"\\n\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GJb0kltZihKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "54ec7506-d74c-4f87-e3b9-74a05fa61718"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-884f933eac40>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiming_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiming_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtiming_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mtotal_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_arima.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define MAXCHAR 1000\n",
        "\n",
        "\n",
        "void readCsv(float *dest, size_t n){\n",
        "    FILE *fp;\n",
        "    char row[MAXCHAR];\n",
        "    char *token;\n",
        "    int ARRAY_SIZE = n;\n",
        "    int i = 0, col = 1;\n",
        "\n",
        "\n",
        "    fp = fopen(\"dataset.txt\",\"r\");\n",
        "\n",
        "    while (feof(fp) != true)\n",
        "    {\n",
        "        fgets(row, MAXCHAR, fp);\n",
        "        token = strtok(row, \",\");\n",
        "        col = 1;\n",
        "        while(token != NULL)\n",
        "        {\n",
        "            if (col == 2)\n",
        "            {\n",
        "                dest[i] = atof(token);\n",
        "                i++;\n",
        "            }\n",
        "            token = strtok(NULL, \",\");\n",
        "            col++;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void writeCsv(float *dest, size_t n){\n",
        "    FILE *fp;\n",
        "    int ARRAY_SIZE = n;\n",
        "    int i;\n",
        "\n",
        "    fp = fopen(\"diff_dataset.txt\",\"w\");\n",
        "\n",
        "    for(i = 0; i < ARRAY_SIZE; i++){\n",
        "        fprintf(fp, \"%f\\n\", dest[i]);\n",
        "    }\n",
        "\n",
        "    fclose(fp);\n",
        "}\n",
        "\n",
        "\n",
        "//CUDA convolution kernel\n",
        "__global__\n",
        "void differencing(size_t n, float *out, float *in){\n",
        "    int k;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for (k = index; k < n-1; k += stride)\n",
        "       out[k]= in[k+1]-in[k];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "  //dataset\n",
        "  const size_t ARRAY_SIZE = 1<<26;\n",
        "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  const size_t numOfLoops = 20;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  // declare arrays\n",
        "    float *in, *out;\n",
        "    cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "    cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "\n",
        "\n",
        "    //readCsv(in, ARRAY_SIZE);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  //get GPU id\n",
        "    int device = -1;\n",
        "    cudaGetDevice(&device);\n",
        "\n",
        "  // memory advise\n",
        "   cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "   cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  //\"prefetch data\" to create CPU page memory\n",
        "    cudaMemPrefetchAsync(in,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  //\"prefetch data\" to create GPU page memory\n",
        "    cudaMemPrefetchAsync(out,ARRAY_BYTES,device,NULL);\n",
        "\n",
        "  // initialize array\n",
        "  for (size_t i=0; i<ARRAY_SIZE; i++)\n",
        "     in[i] = i % 5 + 1.0;\n",
        "\n",
        "  // prefetch from CPU to GPU\n",
        "  cudaMemPrefetchAsync(in,ARRAY_BYTES,device,NULL);\n",
        "\n",
        "  // CUDA kernel\n",
        "    size_t numThreads = 1024;\n",
        "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
        "\n",
        "  printf(\"\\n***** Differencing in CUDA with MemAdvise\\n\");\n",
        "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
        "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
        "    for (size_t i=0; i<numOfLoops;i++)\n",
        "      differencing<<<numBlocks, numThreads>>> (ARRAY_SIZE,out,in);\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(out,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  // error checking routine\n",
        "    size_t err_count = 0;\n",
        "    for (size_t i=0; i<ARRAY_SIZE-2; i++){\n",
        "      if(in[i+1]-in[i] != out[i])\n",
        "        err_count++;\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "  //Displays First 10 Elements\n",
        "  printf(\"First 10 elements: \\n\");\n",
        "  for (int i = 0; i < 10; i++){\n",
        "    printf(\"%.4f\\n\", out[i]);\n",
        "  }\n",
        "  printf(\"...\\n...\\n...\\n\");\n",
        "\n",
        "  //Displays Last 10 Elements\n",
        "  printf(\"Last 10 elements: \\n\");\n",
        "  for (int i = ARRAY_SIZE-10; i < ARRAY_SIZE; i++){\n",
        "    printf(\"%.4f\\n\", out[i]);\n",
        "  }\n",
        "\n",
        "\n",
        "  printf(\"Error count (Prefetch & MemAdvise): %lu\\n\", err_count);\n",
        "\n",
        "  cudaMemAdvise(out, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(out, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  //\"prefetch data\" to create CPU page memory\n",
        "    cudaMemPrefetchAsync(out,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  // prefetch from CPU to GPU\n",
        "    cudaMemPrefetchAsync(out,ARRAY_BYTES,device,NULL);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "  // write to CSV\n",
        "  writeCsv(out, ARRAY_SIZE);\n",
        "\n",
        "  //free memory\n",
        "    cudaFree(in);\n",
        "    cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "1aihvkpDltG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac6180f-2dae-4bea-daf4-f412cec80e1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_arima.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -arch=sm_75 cuda_arima.cu -o cuda_arima"
      ],
      "metadata": {
        "id": "cv8KaQTxmB-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0afcc0-df6a-4d05-dd0a-e0f8d34ab13e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mcuda_arima.cu(11)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"ARRAY_SIZE\"\u001b[0m was declared but never referenced\n",
            "      int ARRAY_SIZE = n;\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_arima"
      ],
      "metadata": {
        "id": "2WgJ032DmDb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76277de0-6aed-4ce5-aab7-6eaa37f860c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==767== NVPROF is profiling process 767, command: ./cuda_arima\n",
            "\n",
            "***** Differencing in CUDA with MemAdvise\n",
            "numElements = 67108864\n",
            "numBlocks = 65536, numThreads = 1024 \n",
            "First 10 elements: \n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "-4.0000\n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "-4.0000\n",
            "...\n",
            "...\n",
            "...\n",
            "Last 10 elements: \n",
            "-4.0000\n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "-4.0000\n",
            "1.0000\n",
            "1.0000\n",
            "1.0000\n",
            "0.0000\n",
            "Error count (Prefetch & MemAdvise): 0\n",
            "==767== Profiling application: ./cuda_arima\n",
            "==767== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  68.188ms        20  3.4094ms  3.4063ms  3.4140ms  differencing(unsigned long, float*, float*)\n",
            "      API calls:   50.29%  250.88ms         2  125.44ms  92.668us  250.79ms  cudaMallocManaged\n",
            "                   22.83%  113.91ms         6  18.986ms  1.1802ms  60.349ms  cudaMemPrefetchAsync\n",
            "                   17.09%  85.252ms         2  42.626ms  17.118ms  68.134ms  cudaDeviceSynchronize\n",
            "                    4.77%  23.789ms         2  11.894ms  11.255ms  12.533ms  cudaFree\n",
            "                    4.56%  22.736ms         4  5.6840ms  4.3660us  19.012ms  cudaMemAdvise\n",
            "                    0.37%  1.8335ms         1  1.8335ms  1.8335ms  1.8335ms  cuDeviceGetPCIBusId\n",
            "                    0.06%  296.05us        20  14.802us  3.2170us  217.74us  cudaLaunchKernel\n",
            "                    0.04%  179.25us       114  1.5720us     103ns  87.158us  cuDeviceGetAttribute\n",
            "                    0.00%  11.326us         1  11.326us  11.326us  11.326us  cuDeviceGetName\n",
            "                    0.00%  1.9740us         1  1.9740us  1.9740us  1.9740us  cudaGetDevice\n",
            "                    0.00%  1.1940us         3     398ns     134ns     820ns  cuDeviceGetCount\n",
            "                    0.00%     793ns         2     396ns     108ns     685ns  cuDeviceGet\n",
            "                    0.00%     513ns         1     513ns     513ns     513ns  cuModuleGetLoadingMode\n",
            "                    0.00%     371ns         1     371ns     371ns     371ns  cuDeviceTotalMem\n",
            "                    0.00%     271ns         1     271ns     271ns     271ns  cuDeviceGetUuid\n",
            "\n",
            "==767== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     256  2.0000MB  2.0000MB  2.0000MB  512.0000MB  44.54922ms  Host To Device\n",
            "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  20.57425ms  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lagged.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "void writeCsv(float *dest, size_t n){\n",
        "    FILE *fp;\n",
        "    int ARRAY_SIZE = n;\n",
        "    int i;\n",
        "\n",
        "    fp = fopen(\"AR_COEFF.txt\",\"w\");\n",
        "\n",
        "    for(i = 0; i < ARRAY_SIZE; i++){\n",
        "        fprintf(fp, \"%f\\n\", dest[i]);\n",
        "    }\n",
        "\n",
        "    fclose(fp);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void autoregressive(size_t n, float *lagged, float *in, int lagged_cols)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // Row index\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // Column index\n",
        "\n",
        "    int rowStride = blockDim.y * gridDim.y;\n",
        "    int colStride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for (int i = row; i < n; i+= rowStride){\n",
        "      for (int j = col; j < lagged_cols; j+= colStride){\n",
        "        if (j == 0){\n",
        "          lagged[i * lagged_cols + j] = 1;\n",
        "        }else if (i < n && j < lagged_cols) {\n",
        "            int index = i - j;\n",
        "            if (index < 0) {\n",
        "                lagged[i * lagged_cols + j] = 0; // Assign zero for out-of-bounds indices\n",
        "            } else {\n",
        "                lagged[i * lagged_cols + j] = in[index]; // Assign lagged value\n",
        "            }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__\n",
        "void transpose(float *out, float *in, int p, size_t ARRAY_SIZE){\n",
        "\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  if (row < p && col < ARRAY_SIZE) {\n",
        "      out[row * ARRAY_SIZE + col] = in[col * p + row];\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "__global__\n",
        "void matMulNaive(float *dest, float *in1, float *in2,\n",
        "                 size_t in1_height, size_t in2_height,\n",
        "                 size_t in1_width, size_t in2_width)\n",
        "{\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Each thread computes one element of the result matrix\n",
        "    float cValue = 0;\n",
        "\n",
        "    if (row < in1_height && col < in2_width) {\n",
        "        // Matrix multiplication: in1 (lagged_cols x n) * in2 (n x lagged_cols)\n",
        "        for (int k = 0; k < in1_width; ++k) {\n",
        "            cValue += in1[row * in1_width + k] * in2[k * in2_width + col];\n",
        "        }\n",
        "        dest[row * in2_width + col] = cValue;\n",
        "    }\n",
        "\n",
        "    //p+1 n x n p+1 -> first mul = p+1 mat\n",
        "    //p+1 p+1 x p+1 n -> second mul = p+1 x n\n",
        "}\n",
        "\n",
        "\n",
        "//Matrix inverse functions\n",
        "__global__ void nodiag_normalize(float *A, float *I, int n, int i){\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n)\n",
        "\tif (x == i && x!=y){\n",
        "\t\tI[x*n + y] /= A[i*n + i];\n",
        "\t\tA[x*n + y] /= A[i*n + i];\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void diag_normalize(float *A, float *I, int n, int i){\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n)\n",
        "\tif (x == y && x == i){\n",
        "\t\tI[x*n + y] /= A[i*n + i];\n",
        "\t\tA[x*n + y] /= A[i*n + i];\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void gaussjordan(float *A, float *I, int n, int i)\n",
        "{\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n){\n",
        "\t\tif (x != i){\n",
        "\t\t\tI[x*n + y] -= I[i*n + y] * A[x*n + i];\n",
        "\t\t\tif (y != i){\n",
        "\t\t\t\tA[x*n + y] -= A[i*n + y] * A[x*n + i];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void set_zero(float *A, float *I, int n, int i){\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n){\n",
        "\t\tif (x != i){\n",
        "\t\t\tif (y == i){\n",
        "\t\t\t\tA[x*n + y] = 0;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main (){\n",
        "\n",
        "  //dataset\n",
        "  const size_t ARRAY_SIZE = 10;\n",
        "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "  //const size_t numOfLoops = 30;\n",
        "\n",
        "\n",
        "  //arima parameters and variables;\n",
        "\n",
        "  const int p = 4;\n",
        "  const int lagged_cols = p + 1;\n",
        "  const int q = 1;\n",
        "\n",
        "  const size_t AR_SIZE = p + 1;\n",
        "  const size_t AR_BYTES = AR_SIZE * sizeof(float);\n",
        "  const size_t X_BYTES = ARRAY_SIZE * lagged_cols * sizeof(float);\n",
        "  const size_t PXP_BYTES = AR_SIZE * AR_SIZE * sizeof(float);\n",
        "\n",
        "  // declare arrays\n",
        "  float *in, *out, *lagged, *transposed, *transposed2,\n",
        "        *prod1, *inverse, *identity, *prod2, *AR_COEFF;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&lagged, X_BYTES); //same amount of rows and p cols\n",
        "  cudaMallocManaged(&transposed,X_BYTES);\n",
        "  cudaMallocManaged(&transposed2,X_BYTES);\n",
        "  cudaMallocManaged(&prod2,X_BYTES);\n",
        "  cudaMallocManaged(&prod1,PXP_BYTES);\n",
        "  cudaMallocManaged(&inverse,PXP_BYTES);\n",
        "  cudaMallocManaged(&identity,PXP_BYTES);\n",
        "  cudaMallocManaged(&AR_COEFF, AR_BYTES);\n",
        "\n",
        "\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);  //get GPU id\n",
        "\n",
        "  // memory advise\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(in,ARRAY_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(lagged,ARRAY_SIZE * lagged_cols * sizeof(float),device,NULL);         //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  for (size_t i=0; i<ARRAY_SIZE; i++)\n",
        "      in[i] = i % 5 + 1.0;\n",
        "\n",
        "  cudaMemPrefetchAsync(in,ARRAY_BYTES,device,NULL);                                //prefetch from CPU to GPU\n",
        "\n",
        "  dim3 threadsPerBlock(16, 16);\n",
        "  dim3 numBlocks((ARRAY_SIZE + threadsPerBlock.x-1)/threadsPerBlock.x,\n",
        "                 (lagged_cols + threadsPerBlock.y-1)/threadsPerBlock.y);\n",
        "\n",
        "  autoregressive<<<numBlocks, threadsPerBlock>>> (ARRAY_SIZE,lagged, in, lagged_cols);\n",
        "  cudaGetLastError();\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(lagged,ARRAY_SIZE * lagged_cols * sizeof(float),cudaCpuDeviceId,NULL);\n",
        "\n",
        "\n",
        "  for (int i = ARRAY_SIZE-10; i < ARRAY_SIZE; i++){\n",
        "    for (int j = 0; j < lagged_cols; j++){\n",
        "      printf(\"%.2f \", lagged[i*lagged_cols+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  //---------- Transposing lagged matrix ----------------//\n",
        "  //try removing later along with prev prefetch async and print\n",
        "\n",
        "\n",
        "  cudaMemAdvise(lagged, X_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(lagged, X_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(lagged,X_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(transposed,X_BYTES, device, NULL);                                   //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(lagged, X_BYTES, device, NULL);\n",
        "\n",
        "\n",
        "  //dim3 dimGrid(ARRAY_SIZE/TILE_DIM, p/TILE_DIM, 1);\n",
        "  //dim3 dimBlock(TILE_DIM, BLOCK_ROWS, 1);\n",
        "\n",
        "  transpose<<<numBlocks, threadsPerBlock>>>(transposed, lagged, lagged_cols, ARRAY_SIZE);\n",
        "  cudaGetLastError();\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(transposed,X_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "\n",
        "  //---printing tranposed---//\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  for (int i = 0; i < lagged_cols; i++){\n",
        "    for (int j = 0; j < 10; j++){\n",
        "      printf(\"%.2f \", transposed[i*ARRAY_SIZE+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(lagged, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(transposed, X_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(prod1, transposed, lagged,\n",
        "                                              lagged_cols, ARRAY_SIZE, ARRAY_SIZE, lagged_cols);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  // Print results if needed\n",
        "  printf(\"\\nMatrix multiplication result:\\n\");\n",
        "  for (int i = 0; i < lagged_cols; i++) {\n",
        "      for (int j = 0; j < lagged_cols; j++) {\n",
        "          printf(\"%.2f \", prod1[i * lagged_cols + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  dim3 threadsPerBlockInv(lagged_cols, lagged_cols);\n",
        "  dim3 numBlocksInv((lagged_cols + lagged_cols -1) / lagged_cols,\n",
        "                 (lagged_cols+lagged_cols-1)/lagged_cols);\n",
        "\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, device, NULL);\n",
        "\n",
        "  //set identity matrix\n",
        "  for (int i = 0; i < lagged_cols; i++){\n",
        "    for (int j = 0; j < lagged_cols; j++){\n",
        "      if (i == j)\n",
        "        inverse[i * lagged_cols + j] = 1.0;\n",
        "      else\n",
        "        inverse[i * lagged_cols + j] = 0.0;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"\\nIdentity Matrix result:\\n\");\n",
        "  for (int i = 0; i < lagged_cols; i++) {\n",
        "      for (int j = 0; j < lagged_cols; j++) {\n",
        "          printf(\"%.2f \", inverse[i * lagged_cols + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "  for (int i = 0; i < lagged_cols; i++){\n",
        "    nodiag_normalize <<<numBlocksInv, threadsPerBlockInv >>>(prod1, inverse, lagged_cols, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tdiag_normalize <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse, lagged_cols, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tgaussjordan <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse,lagged_cols, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tset_zero <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse, lagged_cols, i);\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  printf(\"\\nInverse result:\\n\");\n",
        "  for (int i = 0; i < lagged_cols; i++) {\n",
        "      for (int j = 0; j < lagged_cols; j++) {\n",
        "          printf(\"%.9f \", inverse[i * lagged_cols + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(transposed, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(prod2, inverse, transposed, lagged_cols, lagged_cols, lagged_cols, ARRAY_SIZE);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  printf(\"\\n\");\n",
        "  // Print results if needed\n",
        "  for (int i = 0; i < lagged_cols; i++){\n",
        "    for (int j = 0; j < 10; j++){\n",
        "      printf(\"%.9f \", prod2[i*ARRAY_SIZE+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(AR_COEFF, AR_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(AR_COEFF, prod2, in, lagged_cols, ARRAY_SIZE, ARRAY_SIZE, 1);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(AR_COEFF, X_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  for (int i = 0; i < lagged_cols; i++){\n",
        "    printf(\"%.5f\\n\", AR_COEFF[i]);\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  //cudaDeviceSynchronize();\n",
        "\n",
        "  // write to CSV\n",
        "  writeCsv(AR_COEFF, lagged_cols);\n",
        "\n",
        "\n",
        "  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  cudaFree(lagged);\n",
        "  cudaFree(transposed);\n",
        "  cudaFree(prod1);\n",
        "  cudaFree(prod2);\n",
        "  cudaFree(inverse);\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqRn9B7OnU9Q",
        "outputId": "9344a30a-19c5-4cb3-e406-9a473001cf91"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lagged.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -arch=sm_75 lagged.cu -o lagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDUEhIUhnaQW",
        "outputId": "f68c055c-bfaa-4f96-8a58-d12fd6de36c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mlagged.cu(148)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q\"\u001b[0m was declared but never referenced\n",
            "    const int q = 1;\n",
            "              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./lagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6xUBSEAncKt",
        "outputId": "3c6f25c2-3859-4785-b8ae-0fa8d66f0dd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1131== NVPROF is profiling process 1131, command: ./lagged\n",
            "1.00 0.00 0.00 0.00 0.00 \n",
            "1.00 1.00 0.00 0.00 0.00 \n",
            "1.00 2.00 1.00 0.00 0.00 \n",
            "1.00 3.00 2.00 1.00 0.00 \n",
            "1.00 4.00 3.00 2.00 1.00 \n",
            "1.00 5.00 4.00 3.00 2.00 \n",
            "1.00 1.00 5.00 4.00 3.00 \n",
            "1.00 2.00 1.00 5.00 4.00 \n",
            "1.00 3.00 2.00 1.00 5.00 \n",
            "1.00 4.00 3.00 2.00 1.00 \n",
            "\n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "0.00 1.00 2.00 3.00 4.00 5.00 1.00 2.00 3.00 4.00 \n",
            "0.00 0.00 1.00 2.00 3.00 4.00 5.00 1.00 2.00 3.00 \n",
            "0.00 0.00 0.00 1.00 2.00 3.00 4.00 5.00 1.00 2.00 \n",
            "0.00 0.00 0.00 0.00 1.00 2.00 3.00 4.00 5.00 1.00 \n",
            "\n",
            "Matrix multiplication result:\n",
            "10.00 25.00 21.00 18.00 16.00 \n",
            "25.00 85.00 65.00 51.00 44.00 \n",
            "21.00 65.00 69.00 53.00 43.00 \n",
            "18.00 51.00 53.00 60.00 47.00 \n",
            "16.00 44.00 43.00 47.00 56.00 \n",
            "\n",
            "Identity Matrix result:\n",
            "1.00 0.00 0.00 0.00 0.00 \n",
            "0.00 1.00 0.00 0.00 0.00 \n",
            "0.00 0.00 1.00 0.00 0.00 \n",
            "0.00 0.00 0.00 1.00 0.00 \n",
            "0.00 0.00 0.00 0.00 1.00 \n",
            "\n",
            "Inverse result:\n",
            "0.439719111 -0.092227302 -0.016625991 -0.020980148 -0.022794995 \n",
            "-0.092227288 0.062221933 -0.034666050 0.006436187 -0.001321231 \n",
            "-0.016626017 -0.034666050 0.079890825 -0.038300183 0.002787953 \n",
            "-0.020980153 0.006436189 -0.038300179 0.080425262 -0.037153382 \n",
            "-0.022794986 -0.001321232 0.002787946 -0.037153378 0.054449663 \n",
            "\n",
            "0.439719111 0.347491801 0.238638535 0.108805075 -0.043823361 -0.196451813 0.112056270 0.042557821 -0.005169902 -0.043823361 \n",
            "-0.092227288 -0.030005354 -0.002449472 0.031542595 0.064213425 0.096884280 -0.181554556 0.024446538 0.024936439 0.064213425 \n",
            "-0.016626017 -0.051292069 -0.006067291 0.000857297 0.010569846 0.020282395 0.203325182 -0.186416402 0.014797062 0.010569846 \n",
            "-0.020980153 -0.014543965 -0.046407953 0.002153315 0.013561208 0.024969094 0.004196052 0.207104847 -0.183613598 0.013561208 \n",
            "-0.022794986 -0.024116218 -0.022649504 -0.058336169 -0.039573170 -0.020810172 0.004558980 0.009382248 0.213912144 -0.039573170 \n",
            "1.98226\n",
            "0.51558\n",
            "-0.10141\n",
            "-0.12485\n",
            "0.10405\n",
            "==1131== Profiling application: ./lagged\n",
            "==1131== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   32.90%  121.18us         1  121.18us  121.18us  121.18us  autoregressive(unsigned long, float*, float*, int)\n",
            "                   23.74%  87.455us         3  29.151us  4.1920us  48.159us  matMulNaive(float*, float*, float*, unsigned long, unsigned long, unsigned long, unsigned long)\n",
            "                   21.29%  78.430us         5  15.686us  3.7440us  62.494us  nodiag_normalize(float*, float*, int, int)\n",
            "                   10.05%  37.023us         1  37.023us  37.023us  37.023us  transpose(float*, float*, int, unsigned long)\n",
            "                    4.40%  16.223us         5  3.2440us  3.0080us  3.3590us  gaussjordan(float*, float*, int, int)\n",
            "                    4.15%  15.296us         5  3.0590us  3.0400us  3.1040us  diag_normalize(float*, float*, int, int)\n",
            "                    3.46%  12.736us         5  2.5470us  2.4960us  2.6240us  set_zero(float*, float*, int, int)\n",
            "      API calls:   99.18%  248.17ms        10  24.817ms  6.0850us  248.05ms  cudaMallocManaged\n",
            "                    0.27%  672.76us        25  26.910us  5.5700us  450.97us  cudaLaunchKernel\n",
            "                    0.20%  507.94us        25  20.317us  6.0240us  133.16us  cudaDeviceSynchronize\n",
            "                    0.20%  501.39us        22  22.790us     917ns  126.14us  cudaMemPrefetchAsync\n",
            "                    0.08%  197.16us       114  1.7290us     195ns  76.239us  cuDeviceGetAttribute\n",
            "                    0.04%  108.61us         7  15.515us  10.866us  39.163us  cudaFree\n",
            "                    0.02%  46.956us         4  11.739us  2.3190us  35.759us  cudaMemAdvise\n",
            "                    0.00%  10.571us         1  10.571us  10.571us  10.571us  cuDeviceGetName\n",
            "                    0.00%  8.4050us         1  8.4050us  8.4050us  8.4050us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.9480us         1  2.9480us  2.9480us  2.9480us  cudaGetDevice\n",
            "                    0.00%  1.5330us         3     511ns     235ns  1.0200us  cuDeviceGetCount\n",
            "                    0.00%  1.5210us         5     304ns     238ns     354ns  cudaGetLastError\n",
            "                    0.00%     891ns         2     445ns     191ns     700ns  cuDeviceGet\n",
            "                    0.00%     415ns         1     415ns     415ns     415ns  cuDeviceTotalMem\n",
            "                    0.00%     368ns         1     368ns     368ns     368ns  cuModuleGetLoadingMode\n",
            "                    0.00%     316ns         1     316ns     316ns     316ns  cuDeviceGetUuid\n",
            "\n",
            "==1131== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       3  4.0000KB  4.0000KB  4.0000KB  12.00000KB  9.024000us  Host To Device\n",
            "       6  4.0000KB  4.0000KB  4.0000KB  24.00000KB  11.04000us  Device To Host\n",
            "       6         -         -         -           -  282.7160us  Gpu page fault groups\n",
            "       1  4.0000KB  4.0000KB  4.0000KB  4.000000KB           -  Memory thrashes\n",
            "Total CPU Page faults: 3\n",
            "Total CPU thrashes: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ARIMA.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define MAXCHAR 1000\n",
        "\n",
        "void readCsv(float *dest, size_t n){\n",
        "    FILE *fp;\n",
        "    char row[MAXCHAR];\n",
        "    char *token;\n",
        "    int ARRAY_SIZE = n;\n",
        "    int i = 0, col = 1;\n",
        "\n",
        "\n",
        "    fp = fopen(\"diff_dataset.txt\",\"r\");\n",
        "\n",
        "    while (feof(fp) != true)\n",
        "    {\n",
        "        fgets(row, MAXCHAR, fp);\n",
        "        token = strtok(row, \",\");\n",
        "        col = 1;\n",
        "        while(token != NULL)\n",
        "        {\n",
        "            if (col == 2)\n",
        "            {\n",
        "                dest[i] = atof(token);\n",
        "                i++;\n",
        "            }\n",
        "            token = strtok(NULL, \",\");\n",
        "            col++;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void readCsvAR(float *dest, size_t n){\n",
        "    FILE *fp;\n",
        "    char row[MAXCHAR];\n",
        "    char *token;\n",
        "    int ARRAY_SIZE = n;\n",
        "    int i = 0, col = 1;\n",
        "\n",
        "\n",
        "    fp = fopen(\"AR_COEFF.txt\",\"r\");\n",
        "\n",
        "    while (feof(fp) != true)\n",
        "    {\n",
        "        fgets(row, MAXCHAR, fp);\n",
        "        token = strtok(row, \",\");\n",
        "        col = 1;\n",
        "        while(token != NULL)\n",
        "        {\n",
        "            if (col == 2)\n",
        "            {\n",
        "                dest[i] = atof(token);\n",
        "                i++;\n",
        "            }\n",
        "            token = strtok(NULL, \",\");\n",
        "            col++;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// FORECASTING\n",
        "void ARIMA(float *out, float *dataset, float *residuals, float *AR_coeff, float *MA_coeff, size_t p, size_t q, size_t ARRAY_SIZE, size_t Prediction_Size){\n",
        "    for(int i = 0; i < Prediction_Size; i++){\n",
        "        float ar = 0;\n",
        "        float ma = 0;\n",
        "\n",
        "        for(int j = 0; j < p; j++){\n",
        "            ar += AR_coeff[j] * dataset[i+ARRAY_SIZE-j];\n",
        "        }\n",
        "\n",
        "        for(int j = 0; j < q; j++){\n",
        "            ma += MA_coeff[j] * residuals[i+ARRAY_SIZE-j];\n",
        "        }\n",
        "\n",
        "        // Get new Prediction\n",
        "        out[i] = ar + ma;\n",
        "\n",
        "        // Get new residuals\n",
        "        residuals[i+ARRAY_SIZE] = dataset[i+ARRAY_SIZE] - out[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    //dataset\n",
        "    const size_t ARRAY_SIZE = 1<<10;\n",
        "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "    const size_t AR_BYTES = 5 * sizeof(float);\n",
        "    const size_t MA_BYTES = 5 * sizeof(float);\n",
        "    const size_t Prediction_Size = 10;\n",
        "    const size_t Prediction_Bytes = Prediction_Size * sizeof(float);\n",
        "    //const size_t numOfLoops = 30;\n",
        "\n",
        "    // declare arrays\n",
        "    float *dataset, *residuals, *AR_coeff, *MA_coeff, *out;\n",
        "    cudaMallocManaged(&dataset, ARRAY_BYTES);\n",
        "    cudaMallocManaged(&residuals, ARRAY_BYTES + Prediction_Bytes);\n",
        "    cudaMallocManaged(&AR_coeff, AR_BYTES);\n",
        "    cudaMallocManaged(&MA_coeff, MA_BYTES);\n",
        "\n",
        "    cudaMallocManaged(&out, Prediction_Bytes);\n",
        "\n",
        "    int device = -1;\n",
        "    cudaGetDevice(&device);  //get GPU id\n",
        "\n",
        "    // Initialize Dataset\n",
        "    for (size_t i=0; i<ARRAY_SIZE; i++)\n",
        "      dataset[i] = i % 5 + 1.0;\n",
        "\n",
        "    // Initialize residuals\n",
        "    for (size_t i=0; i<ARRAY_SIZE; i++)\n",
        "      residuals[i] = 1 / 5;\n",
        "\n",
        "    // Initialize AR_COEFF\n",
        "\n",
        "    AR_coeff[0] = 1.982260;\n",
        "    AR_coeff[1] = 0.515579;\n",
        "    AR_coeff[2] = -0.101413;\n",
        "    AR_coeff[3] = -0.124845;\n",
        "    AR_coeff[4] = 0.104051;\n",
        "\n",
        "    // Initialize MA_coeff\n",
        "\n",
        "    MA_coeff[0] = 0.17950;\n",
        "    MA_coeff[1] = 0.32938;\n",
        "    MA_coeff[2] = -0.00733;\n",
        "    MA_coeff[3] = -0.04431;\n",
        "    MA_coeff[4] = -0.10458;\n",
        "\n",
        "    ARIMA(out,dataset,residuals,AR_coeff,MA_coeff,5,5,ARRAY_SIZE,Prediction_Size);\n",
        "\n",
        "    printf(\"Predicted Values: \\n\");\n",
        "    for(int i = 0; i < Prediction_Size; i++){\n",
        "      printf(\"%.2f \", out[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoEw--iIoF8j",
        "outputId": "ef4cab11-74b3-45f1-b267-e82681a7443e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ARIMA.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -arch=sm_75 ARIMA.cu -o ARIMA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAdktNtorXpO",
        "outputId": "a7b535e9-df15-47a9-fdc1-7cde31416e55"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mARIMA.cu(10)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"ARRAY_SIZE\"\u001b[0m was declared but never referenced\n",
            "      int ARRAY_SIZE = n;\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mARIMA.cu(38)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"ARRAY_SIZE\"\u001b[0m was declared but never referenced\n",
            "      int ARRAY_SIZE = n;\n",
            "          ^\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./ARIMA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2LrefR9rZKy",
        "outputId": "5f63481b-e8e0-4fad-9d60-c4dbd08b219d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==7455== NVPROF is profiling process 7455, command: ./ARIMA\n",
            "Predicted Values: \n",
            "1.61 -1.10 0.19 0.42 -0.02 -0.10 0.07 0.02 -0.01 -0.00 \n",
            "==7455== Profiling application: ./ARIMA\n",
            "==7455== Profiling result:\n",
            "No kernels were profiled.\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "      API calls:   99.82%  116.07ms         5  23.213ms  3.4580us  116.03ms  cudaMallocManaged\n",
            "                    0.15%  177.38us       114  1.5550us     144ns  70.132us  cuDeviceGetAttribute\n",
            "                    0.01%  14.293us         1  14.293us  14.293us  14.293us  cuDeviceGetName\n",
            "                    0.01%  5.8830us         1  5.8830us  5.8830us  5.8830us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.6780us         1  1.6780us  1.6780us  1.6780us  cudaGetDevice\n",
            "                    0.00%  1.6740us         3     558ns     174ns  1.1660us  cuDeviceGetCount\n",
            "                    0.00%  1.2690us         2     634ns     175ns  1.0940us  cuDeviceGet\n",
            "                    0.00%  1.1630us         1  1.1630us  1.1630us  1.1630us  cuDeviceTotalMem\n",
            "                    0.00%     417ns         1     417ns     417ns     417ns  cuModuleGetLoadingMode\n",
            "                    0.00%     311ns         1     311ns     311ns     311ns  cuDeviceGetUuid\n",
            "\n",
            "==7455== Unified Memory profiling result:\n",
            "Total CPU Page faults: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}