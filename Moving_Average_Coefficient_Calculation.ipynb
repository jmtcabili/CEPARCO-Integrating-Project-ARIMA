{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpm-gn6oV5NG",
        "outputId": "69033b0b-392b-4164-e58d-784acd2da9cf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr  3 03:22:02 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmtrrHgVmhI",
        "outputId": "69fcc659-65f7-4742-a1f3-cf727a337d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting coeff_ma.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile coeff_ma.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "/** AR FUNCTIONS **/\n",
        "__global__\n",
        "void autoregressive(size_t n, float *lagged, float *in, int lagged_cols)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // Row index\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // Column index\n",
        "\n",
        "    int rowStride = blockDim.y * gridDim.y;\n",
        "    int colStride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for (int i = row; i < n; i+= rowStride){\n",
        "      for (int j = col; j < lagged_cols; j+= colStride){\n",
        "        if (j == 0){\n",
        "          lagged[i * lagged_cols + j] = 1;\n",
        "        }else if (i < n && j < lagged_cols) {\n",
        "            int index = i - j;\n",
        "            if (index < 0) {\n",
        "                lagged[i * lagged_cols + j] = 0; // Assign zero for out-of-bounds indices\n",
        "            } else {\n",
        "                lagged[i * lagged_cols + j] = in[index]; // Assign lagged value\n",
        "            }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__\n",
        "void transpose(float *out, float *in, int p, size_t ARRAY_SIZE){\n",
        "\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  if (row < p && col < ARRAY_SIZE) {\n",
        "      out[row * ARRAY_SIZE + col] = in[col * p + row];\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "__global__\n",
        "void matMulNaive(float *dest, float *in1, float *in2,\n",
        "                 size_t in1_height, size_t in2_height,\n",
        "                 size_t in1_width, size_t in2_width)\n",
        "{\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Each thread computes one element of the result matrix\n",
        "    float cValue = 0;\n",
        "\n",
        "    if (row < in1_height && col < in2_width) {\n",
        "        // Matrix multiplication: in1 (lagged_cols x n) * in2 (n x lagged_cols)\n",
        "        for (int k = 0; k < in1_width; ++k) {\n",
        "            cValue += in1[row * in1_width + k] * in2[k * in2_width + col];\n",
        "        }\n",
        "        dest[row * in2_width + col] = cValue;\n",
        "    }\n",
        "\n",
        "    //p+1 n x n p+1 -> first mul = p+1 mat\n",
        "    //p+1 p+1 x p+1 n -> second mul = p+1 x n\n",
        "}\n",
        "\n",
        "\n",
        "//Matrix inverse functions\n",
        "__global__ void nodiag_normalize(float *A, float *I, int n, int i){\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n)\n",
        "\tif (x == i && x!=y){\n",
        "\t\tI[x*n + y] /= A[i*n + i];\n",
        "\t\tA[x*n + y] /= A[i*n + i];\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void diag_normalize(float *A, float *I, int n, int i){\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n)\n",
        "\tif (x == y && x == i){\n",
        "\t\tI[x*n + y] /= A[i*n + i];\n",
        "\t\tA[x*n + y] /= A[i*n + i];\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void gaussjordan(float *A, float *I, int n, int i)\n",
        "{\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n){\n",
        "\t\tif (x != i){\n",
        "\t\t\tI[x*n + y] -= I[i*n + y] * A[x*n + i];\n",
        "\t\t\tif (y != i){\n",
        "\t\t\t\tA[x*n + y] -= A[i*n + y] * A[x*n + i];\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "}\n",
        "\n",
        "__global__ void set_zero(float *A, float *I, int n, int i){\n",
        "\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (x < n && y < n){\n",
        "\t\tif (x != i){\n",
        "\t\t\tif (y == i){\n",
        "\t\t\t\tA[x*n + y] = 0;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "/** MA functions **/\n",
        "\n",
        "__global__\n",
        "void calcuate_rate(size_t n, float *out, float *in){\n",
        "    int k;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    for (k = index; k < n; k += stride){\n",
        "      if(k<1)\n",
        "          out[k] = 0.0f;\n",
        "      else\n",
        "       out[k]= in[k]/in[k-1]-1;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "//output is sum , averaging is done externally\n",
        "__global__\n",
        "void  getTotalSum(size_t n, float *avesum ,float *in){\n",
        "  __shared__ float sum;\n",
        "    int k;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    sum = 0.0;\n",
        "\n",
        "    for (k = index; k < n; k +=  stride){\n",
        "      atomicAdd(&sum, in[k]);\n",
        "      __syncthreads();\n",
        "\n",
        "      if(index % blockDim.x ==0){\n",
        "        atomicAdd(avesum,sum);\n",
        "      }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "__global__\n",
        "void  calculate_residuals(size_t n, float *out ,float *in, float *average ){\n",
        "    int k;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int stride = blockDim.x * gridDim.x;\n",
        "    for (k = index; k < n; k += stride){\n",
        "      if(k<1)\n",
        "          out[k] = 0.0f;\n",
        "      else\n",
        "          out[index] = in[index]- *average;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void calres(float *arrout, float *resids, float *coeff,float *laggedresids, int numLags, int n)\n",
        "{\n",
        "\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "  int rowStride = blockDim.y * gridDim.y;\n",
        "  int colStride = blockDim.x * gridDim.x;\n",
        "  float constant = coeff[0]; // constant is always the first element in the coefficients\n",
        "  float sum = 0;\n",
        "  float final = 0.0;\n",
        "\n",
        "  __shared__ float tempSums;\n",
        "\n",
        "    for (int i = row; i < n; i+= rowStride){\n",
        "        tempSums = 0.0f;\n",
        "      for (int j = col; j < numLags; j+= colStride){\n",
        "        if (i < n && j < numLags && j != 0) {\n",
        "            sum= laggedresids[i * numLags + j] *coeff[j];   // sumprod of coeff and laggedresids\n",
        "            atomicAdd(&tempSums,sum);\n",
        "        }\n",
        "        final = constant + resids[i * numLags + j] + tempSums;  // residuals calculation\n",
        "\n",
        "        if(j+1>=numLags) //store the final answer\n",
        "          atomicAdd(&arrout[i],final);\n",
        "\n",
        "        __syncthreads();\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "  //dataset\n",
        "  const size_t ARRAY_SIZE = 100;\n",
        "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "\n",
        "  const int p = 4;\n",
        "  const int lagged_cols = p + 1;\n",
        "  const int q = 4;\n",
        "  const int lagged_q = q+1;\n",
        "\n",
        "\n",
        "  //ma parameters\n",
        "  const size_t MA_SIZE = q+1;\n",
        "  const size_t MA_BYTES = MA_SIZE * sizeof(float);\n",
        "  const size_t TWOD_BYTES = ARRAY_SIZE * lagged_q * sizeof(float);\n",
        "\n",
        "  //ma arrays\n",
        "  float *in, *out, *rate, *residuals_first, *laggingResids_first,\n",
        "  *residuals_next, *laggingResids_next, *ma_coeff, *totalSum, *residaverage;\n",
        "  cudaMallocManaged(&residaverage,sizeof(float));\n",
        "  cudaMallocManaged(&totalSum,sizeof(float));\n",
        "  cudaMallocManaged(&ma_coeff,MA_BYTES);\n",
        "  cudaMallocManaged(&in,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&rate,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&residuals_first,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&laggingResids_first,TWOD_BYTES);\n",
        "  cudaMallocManaged(&residuals_next,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&laggingResids_next,TWOD_BYTES);\n",
        "\n",
        "  //ar PART\n",
        "  const size_t AR_SIZE = p + 1;\n",
        "  const size_t AR_BYTES = AR_SIZE * sizeof(float);\n",
        "  const size_t X_BYTES = ARRAY_SIZE * lagged_q * sizeof(float);\n",
        "  const size_t PXP_BYTES = MA_SIZE * MA_SIZE * sizeof(float);\n",
        "\n",
        "\n",
        "  // declare arrays\n",
        "  float *lagged, *transposed, *transposed2,\n",
        "        *prod1, *inverse, *identity, *prod2, *AR_COEFF;\n",
        "  cudaMallocManaged(&in, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&lagged, X_BYTES); //same amount of rows and p cols\n",
        "  cudaMallocManaged(&transposed,X_BYTES);\n",
        "  cudaMallocManaged(&transposed2,X_BYTES);\n",
        "  cudaMallocManaged(&prod2,X_BYTES);\n",
        "  cudaMallocManaged(&prod1,PXP_BYTES);\n",
        "  cudaMallocManaged(&inverse,PXP_BYTES);\n",
        "  cudaMallocManaged(&identity,PXP_BYTES);\n",
        "  cudaMallocManaged(&AR_COEFF, AR_BYTES);\n",
        "\n",
        "\n",
        "\n",
        "  // DEVICE INFO\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);  //get GPU id\n",
        "\n",
        "\n",
        "  // memory advise\n",
        "   cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "   cudaMemAdvise(in, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  //\"prefetch data\" to create CPU page memory\n",
        "    cudaMemPrefetchAsync(in,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  //\"prefetch data\" to create GPU page memory\n",
        "    cudaMemPrefetchAsync(rate,ARRAY_BYTES,device,NULL);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(in,ARRAY_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(rate,ARRAY_BYTES,device,NULL);         //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  for (size_t i=0; i<ARRAY_SIZE; i++)\n",
        "       in[i] = i % 5 + 1.0;\n",
        "\n",
        "  printf(\"First 10 elements of input data \\n\");\n",
        "  for (int i = 0; i < 10; i++){\n",
        "    printf(\"%.5f\\n\", in[i]);}\n",
        "\n",
        "  //Displays Last 10 Elements\n",
        "  printf(\"Last 10 elements: \\n\");\n",
        "  for (int i = ARRAY_SIZE-10; i < ARRAY_SIZE; i++){\n",
        "    printf(\"%.5f\\n\", in[i]);\n",
        "  }\n",
        "\n",
        "\n",
        "  //******************FIRST -- CALCULATE RATE\n",
        "  cudaMemPrefetchAsync(in,ARRAY_BYTES,device,NULL);                                //prefetch from CPU to GPU\n",
        "  size_t numThreads = 1024;\n",
        "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
        "\n",
        "  calcuate_rate<<<numBlocks, numThreads>>>(ARRAY_SIZE,rate,in);\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(rate,ARRAY_SIZE,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  printf(\"First 10 elements of rate \\n\");\n",
        "  for (int i = 0; i < 10; i++){\n",
        "    printf(\"%.5f\\n\", rate[i]);\n",
        "  }\n",
        "\n",
        "   //Displays Last 10 Elements\n",
        "  printf(\"Last 10 elements: \\n\");\n",
        "  for (int i = ARRAY_SIZE-10; i < ARRAY_SIZE; i++){\n",
        "    printf(\"%.5f\\n\", rate[i]);\n",
        "  }\n",
        "\n",
        "\n",
        "  printf(\"...\\n...\\n\\n\");\n",
        "\n",
        "  //********************SECOND -- GET AVERAGE FOR RESIDUALS\n",
        "  // memory advise\n",
        "   cudaMemAdvise(rate, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "   cudaMemAdvise(rate, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  //\"prefetch data\" to create CPU page memory\n",
        "    cudaMemPrefetchAsync(rate,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "  //\"prefetch data\" to create GPU page memory\n",
        "    cudaMemPrefetchAsync(totalSum,sizeof(float),device,NULL);\n",
        "\n",
        "  getTotalSum<<<numBlocks, numThreads>>>(ARRAY_SIZE, totalSum,rate);\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(totalSum,sizeof(float),cudaCpuDeviceId,NULL);\n",
        "\n",
        "  float average = *totalSum/(ARRAY_SIZE-1);\n",
        "  *residaverage = average;\n",
        "  printf(\"The average is %.5f\\n\\n\", average);\n",
        "\n",
        "  //********************THIRD -- FIRST RESIDUALS CALCULATION\n",
        "  // memory advise\n",
        "   cudaMemAdvise(rate, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "   cudaMemAdvise(rate, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  //\"prefetch data\" to create CPU page memory\n",
        "    cudaMemPrefetchAsync(rate,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
        "    cudaMemPrefetchAsync(residaverage,sizeof(float),cudaCpuDeviceId,NULL);\n",
        "\n",
        "  //\"prefetch data\" to create GPU page memory\n",
        "    cudaMemPrefetchAsync(residuals_first,ARRAY_BYTES,device,NULL);\n",
        "\n",
        "    calculate_residuals<<<numBlocks, numThreads>>>(ARRAY_SIZE, residuals_first ,rate,residaverage);\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(residuals_first,ARRAY_SIZE,cudaCpuDeviceId,NULL);\n",
        "\n",
        "  printf(\"First 10 elements of residuals \\n\");\n",
        "  for (int i = 0; i < 10; i++){\n",
        "    printf(\"%.5f\\n\", residuals_first[i]);\n",
        "  }\n",
        "  printf(\"...\\n...\\n\\n\");\n",
        "\n",
        "  //********************FOURTH - CALCULATION OF MA_COEFF && RESIDUALS (LOOPED 5 TIMES)\n",
        "  // lag and populate the results\n",
        "\n",
        "  //********** LAG COMPONENTS\n",
        "  // memory advise\n",
        "  cudaMemAdvise(residuals_first, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(residuals_first, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(residuals_first,ARRAY_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(laggingResids_first,X_BYTES,device,NULL);         //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  dim3 threadsPerBlock(16, 16);\n",
        "  //dim3 numBlocks((ARRAY_SIZE + threadsPerBlock.x-1)/threadsPerBlock.x,\n",
        "  //               (lagged_q + threadsPerBlock.y-1)/threadsPerBlock.y);\n",
        "\n",
        "  autoregressive<<<numBlocks, threadsPerBlock>>> (ARRAY_SIZE,laggingResids_first, residuals_first, lagged_q);\n",
        "  cudaGetLastError();\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(laggingResids_first,X_BYTES,cudaCpuDeviceId,NULL);\n",
        "  printf(\"Lagged residuals \\n\");\n",
        "  for (int i = ARRAY_SIZE-10; i < ARRAY_SIZE; i++){\n",
        "    for (int j = 0; j < lagged_q; j++){\n",
        "      printf(\"%.2f \", laggingResids_first[i*lagged_q+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "  //********** get first coefficients using autoregressive\n",
        "\n",
        "  //---------- Transposing lagged matrix ----------------//\n",
        "  //try removing later along with prev prefetch async and print\n",
        "\n",
        "\n",
        "  cudaMemAdvise(laggingResids_first,X_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(laggingResids_first,X_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(laggingResids_first,X_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(transposed,X_BYTES, device, NULL);                                   //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(laggingResids_first,X_BYTES, device, NULL);\n",
        "\n",
        "\n",
        "  //dim3 dimGrid(ARRAY_SIZE/TILE_DIM, p/TILE_DIM, 1);\n",
        "  //dim3 dimBlock(TILE_DIM, BLOCK_ROWS, 1);\n",
        "\n",
        "  transpose<<<numBlocks, threadsPerBlock>>>(transposed, laggingResids_first, lagged_q, ARRAY_SIZE);\n",
        "  cudaGetLastError();\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(transposed,X_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "\n",
        "  //---printing tranposed---//\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    for (int j = 0; j < 10; j++){\n",
        "      printf(\"%.2f \", transposed[i*ARRAY_SIZE+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(laggingResids_first, TWOD_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(transposed, X_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(prod1, transposed, laggingResids_first,\n",
        "                                              lagged_q, ARRAY_SIZE, ARRAY_SIZE, lagged_q);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  // Print results if needed\n",
        "  printf(\"\\nMatrix multiplication result:\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++) {\n",
        "      for (int j = 0; j < lagged_q; j++) {\n",
        "          printf(\"%.2f \", prod1[i * lagged_q + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  dim3 threadsPerBlockInv(lagged_q, lagged_q);\n",
        "  dim3 numBlocksInv((lagged_q + lagged_q -1) / lagged_q,\n",
        "                 (lagged_q+lagged_q-1)/lagged_q);\n",
        "\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, device, NULL);\n",
        "\n",
        "  //set identity matrix\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    for (int j = 0; j < lagged_q; j++){\n",
        "      if (i == j)\n",
        "        inverse[i * lagged_q + j] = 1.0;\n",
        "      else\n",
        "        inverse[i * lagged_q + j] = 0.0;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"\\nIdentity Matrix result:\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++) {\n",
        "      for (int j = 0; j < lagged_q; j++) {\n",
        "          printf(\"%.2f \", inverse[i * lagged_q + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    nodiag_normalize <<<numBlocksInv, threadsPerBlockInv >>>(prod1, inverse, lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tdiag_normalize <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse, lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tgaussjordan <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse,lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tset_zero <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse, lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  printf(\"\\nInverse result:\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++) {\n",
        "      for (int j = 0; j < lagged_q; j++) {\n",
        "          printf(\"%.9f \", inverse[i * lagged_q + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(transposed, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(prod2, inverse, transposed, lagged_q, lagged_q, lagged_q, ARRAY_SIZE);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  printf(\"\\n\");\n",
        "  // Print results if needed\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    for (int j = 0; j < 10; j++){\n",
        "      printf(\"%.9f \", prod2[i*ARRAY_SIZE+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(ma_coeff, MA_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(ma_coeff, prod2, rate, lagged_q, ARRAY_SIZE, ARRAY_SIZE, 1);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(ma_coeff, MA_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "\n",
        "  printf(\"\\n\\n----Moving Average coefficients----\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    printf(\"%.5f\\n\", ma_coeff[i]);\n",
        "  }\n",
        "\n",
        "///******************* calculate next residuals\n",
        "\n",
        "  // memory advise\n",
        "  cudaMemAdvise(residuals_first, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(residuals_first, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(laggingResids_first, TWOD_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(residuals_first,ARRAY_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(laggingResids_first,TWOD_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(ma_coeff,MA_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(residuals_next,ARRAY_BYTES,device,NULL);         //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  int threadsPerBlock_in = ARRAY_SIZE/16+1;\n",
        "  calres<<<threadsPerBlock_in,16>>>(residuals_next,residuals_first,ma_coeff,laggingResids_first,lagged_q,ARRAY_SIZE);\n",
        "  cudaDeviceSynchronize();  // synchronize GPU with CPU\n",
        "\n",
        "  cudaMemPrefetchAsync(residuals_next,ARRAY_BYTES,cudaCpuDeviceId,NULL);      // prefetch from GPU to CPU\n",
        "\n",
        " //  printf(\"First ten elements of NEW RESIDUALS\\n\");\n",
        "  //for (int i = 0; i < 10; i++){\n",
        "   // printf(\"%.5f\\n\", residuals_next[i]);}\n",
        "\n",
        "//**************** calculate the next coefficients loop #1\n",
        "\n",
        " // memory advise\n",
        "  cudaMemAdvise(residuals_next, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(residuals_next, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(residuals_next,ARRAY_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "  cudaMemPrefetchAsync(laggingResids_first,TWOD_BYTES,device,NULL);         //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "\n",
        "\n",
        "  autoregressive<<<numBlocks, threadsPerBlock>>> (ARRAY_SIZE,laggingResids_first, residuals_next, lagged_q);\n",
        "  cudaGetLastError();\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(laggingResids_first,TWOD_BYTES,cudaCpuDeviceId,NULL);\n",
        "  printf(\"Lagged residuals \\n\");\n",
        "  for (int i = ARRAY_SIZE-10; i < ARRAY_SIZE; i++){\n",
        "    for (int j = 0; j < lagged_q; j++){\n",
        "      printf(\"%.2f \", laggingResids_first[i*lagged_q+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  //---------- Transposing lagged matrix ----------------//\n",
        "  //try removing later along with prev prefetch async and print\n",
        "\n",
        "\n",
        "  cudaMemAdvise(laggingResids_first,TWOD_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(laggingResids_first,TWOD_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(laggingResids_first,TWOD_BYTES,cudaCpuDeviceId,NULL);                       //\"prefetch data\" to create CPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(transposed,X_BYTES, device, NULL);                                   //\"prefetch data\" to create GPU page memory\n",
        "\n",
        "  cudaMemPrefetchAsync(laggingResids_first,TWOD_BYTES, device, NULL);\n",
        "\n",
        "\n",
        "  //dim3 dimGrid(ARRAY_SIZE/TILE_DIM, p/TILE_DIM, 1);\n",
        "  //dim3 dimBlock(TILE_DIM, BLOCK_ROWS, 1);\n",
        "\n",
        "  transpose<<<numBlocks, threadsPerBlock>>>(transposed, laggingResids_first, lagged_q, ARRAY_SIZE);\n",
        "  cudaGetLastError();\n",
        "\n",
        "  // synchronize GPU with CPU\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // prefetch from GPU to CPU\n",
        "  cudaMemPrefetchAsync(transposed,X_BYTES,cudaCpuDeviceId,NULL);\n",
        "\n",
        "\n",
        "  //---printing tranposed---//\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    for (int j = 0; j < 10; j++){\n",
        "      printf(\"%.2f \", transposed[i*ARRAY_SIZE+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(laggingResids_first, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(transposed, X_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(prod1, transposed, laggingResids_first,\n",
        "                                              lagged_q, ARRAY_SIZE, ARRAY_SIZE, lagged_q);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  // Print results if needed\n",
        "  printf(\"\\nMatrix multiplication result:\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++) {\n",
        "      for (int j = 0; j < lagged_q; j++) {\n",
        "          printf(\"%.2f \", prod1[i * lagged_q + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(prod1, PXP_BYTES, device, NULL);\n",
        "\n",
        "  //set identity matrix\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    for (int j = 0; j < lagged_q; j++){\n",
        "      if (i == j)\n",
        "        inverse[i * lagged_q + j] = 1.0;\n",
        "      else\n",
        "        inverse[i * lagged_q + j] = 0.0;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"\\nIdentity Matrix result:\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++) {\n",
        "      for (int j = 0; j < lagged_q; j++) {\n",
        "          printf(\"%.2f \", inverse[i * lagged_q + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    nodiag_normalize <<<numBlocksInv, threadsPerBlockInv >>>(prod1, inverse, lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tdiag_normalize <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse, lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tgaussjordan <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse,lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "\t\tset_zero <<<numBlocksInv, threadsPerBlockInv>>>(prod1, inverse, lagged_q, i);\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  printf(\"\\nInverse result:\\n\");\n",
        "  for (int i = 0; i < lagged_q; i++) {\n",
        "      for (int j = 0; j < lagged_q; j++) {\n",
        "          printf(\"%.9f \", inverse[i * lagged_q + j]);\n",
        "      }\n",
        "      printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(transposed, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(inverse, PXP_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(prod2, inverse, transposed, lagged_q, lagged_q, lagged_q, ARRAY_SIZE);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  printf(\"\\n\");\n",
        "  // Print results if needed\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    for (int j = 0; j < 10; j++){\n",
        "      printf(\"%.9f \", prod2[i*ARRAY_SIZE+j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaMemPrefetchAsync(prod2, X_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(ma_coeff, MA_BYTES, device, NULL);\n",
        "\n",
        "  matMulNaive<<<numBlocks, threadsPerBlock>>>(ma_coeff, prod2, rate, lagged_q, ARRAY_SIZE, ARRAY_SIZE, 1);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaGetLastError();\n",
        "  if (err != cudaSuccess) {\n",
        "      printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "\n",
        "  // Prefetch result back to CPU\n",
        "  printf(\"\\n\\n----Moving Average coefficients II----\\n\");\n",
        "  cudaMemPrefetchAsync(ma_coeff, MA_BYTES, cudaCpuDeviceId, NULL);\n",
        "  for (int i = 0; i < lagged_q; i++){\n",
        "    printf(\"%.5f\\n\", ma_coeff[i]);\n",
        "  }\n",
        "\n",
        "  // free ma\n",
        "  cudaFree(residaverage);\n",
        "  cudaFree(totalSum);\n",
        "  cudaFree(ma_coeff);\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  cudaFree(rate);\n",
        "  cudaFree(residuals_first);\n",
        "  cudaFree(laggingResids_first);\n",
        "  cudaFree(laggingResids_first);\n",
        "  cudaFree(residuals_next);\n",
        "  cudaFree(laggingResids_next);\n",
        "\n",
        "  //free ar  //free memory\n",
        "  cudaFree(in);\n",
        "  cudaFree(out);\n",
        "  cudaFree(lagged);\n",
        "  cudaFree(transposed);\n",
        "  cudaFree(prod1);\n",
        "  cudaFree(prod2);\n",
        "  cudaFree(inverse);\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc -arch=sm_75 coeff_ma.cu -o coeff_ma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lERx7Is8fL-z",
        "outputId": "85f2bb95-1fe7-4d9c-b500-5246bf4598c2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mcoeff_ma.cu(214)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"lagged_cols\"\u001b[0m was declared but never referenced\n",
            "    const int lagged_cols = p + 1;\n",
            "              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./coeff_ma"
      ],
      "metadata": {
        "id": "q3G9vSWdfNd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96953da5-c9e4-4b82-9594-2373b098ed69"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==15583== NVPROF is profiling process 15583, command: ./coeff_ma\n",
            "First 10 elements of input data \n",
            "1.00000\n",
            "2.00000\n",
            "3.00000\n",
            "4.00000\n",
            "5.00000\n",
            "1.00000\n",
            "2.00000\n",
            "3.00000\n",
            "4.00000\n",
            "5.00000\n",
            "Last 10 elements: \n",
            "1.00000\n",
            "2.00000\n",
            "3.00000\n",
            "4.00000\n",
            "5.00000\n",
            "1.00000\n",
            "2.00000\n",
            "3.00000\n",
            "4.00000\n",
            "5.00000\n",
            "First 10 elements of rate \n",
            "0.00000\n",
            "1.00000\n",
            "0.50000\n",
            "0.33333\n",
            "0.25000\n",
            "-0.80000\n",
            "1.00000\n",
            "0.50000\n",
            "0.33333\n",
            "0.25000\n",
            "Last 10 elements: \n",
            "-0.80000\n",
            "1.00000\n",
            "0.50000\n",
            "0.33333\n",
            "0.25000\n",
            "-0.80000\n",
            "1.00000\n",
            "0.50000\n",
            "0.33333\n",
            "0.25000\n",
            "...\n",
            "...\n",
            "\n",
            "The average is 0.26734\n",
            "\n",
            "First 10 elements of residuals \n",
            "0.00000\n",
            "0.73266\n",
            "0.23266\n",
            "0.06599\n",
            "-0.01734\n",
            "-1.06734\n",
            "0.73266\n",
            "0.23266\n",
            "0.06599\n",
            "-0.01734\n",
            "...\n",
            "...\n",
            "\n",
            "Lagged residuals \n",
            "1.00 -0.02 0.07 0.23 0.73 \n",
            "1.00 -1.07 -0.02 0.07 0.23 \n",
            "1.00 0.73 -1.07 -0.02 0.07 \n",
            "1.00 0.23 0.73 -1.07 -0.02 \n",
            "1.00 0.07 0.23 0.73 -1.07 \n",
            "1.00 -0.02 0.07 0.23 0.73 \n",
            "1.00 -1.07 -0.02 0.07 0.23 \n",
            "1.00 0.73 -1.07 -0.02 0.07 \n",
            "1.00 0.23 0.73 -1.07 -0.02 \n",
            "1.00 0.07 0.23 0.73 -1.07 \n",
            "\n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "0.00 0.00 0.73 0.23 0.07 -0.02 -1.07 0.73 0.23 0.07 \n",
            "0.00 0.00 0.00 0.73 0.23 0.07 -0.02 -1.07 0.73 0.23 \n",
            "0.00 0.00 0.00 0.00 0.73 0.23 0.07 -0.02 -1.07 0.73 \n",
            "0.00 0.00 0.00 0.00 0.00 0.73 0.23 0.07 -0.02 -1.07 \n",
            "\n",
            "Matrix multiplication result:\n",
            "16.00 0.91 0.92 0.86 0.63 \n",
            "0.91 4.07 -0.97 -0.53 -0.59 \n",
            "0.92 -0.97 4.06 -0.97 -0.53 \n",
            "0.86 -0.53 -0.97 4.06 -0.99 \n",
            "0.63 -0.59 -0.53 -0.99 4.01 \n",
            "\n",
            "Identity Matrix result:\n",
            "1.00 0.00 0.00 0.00 0.00 \n",
            "0.00 1.00 0.00 0.00 0.00 \n",
            "0.00 0.00 1.00 0.00 0.00 \n",
            "0.00 0.00 0.00 1.00 0.00 \n",
            "0.00 0.00 0.00 0.00 1.00 \n",
            "\n",
            "Inverse result:\n",
            "0.069377743 -0.032634642 -0.035546474 -0.034431644 -0.028771175 \n",
            "-0.032634642 0.306158036 0.115133487 0.095986664 0.088722482 \n",
            "-0.035546474 0.115133487 0.323402733 0.123092584 0.095209114 \n",
            "-0.034431644 0.095986672 0.123092584 0.323583961 0.115334406 \n",
            "-0.028771175 0.088722482 0.095209114 0.115334399 0.308014363 \n",
            "\n",
            "0.069377743 0.069377743 0.045467652 0.035741497 0.033727158 0.038507469 0.095860228 0.082106188 0.072990671 0.064435787 \n",
            "-0.032634642 -0.032634642 0.191675052 0.122949712 0.084682211 0.056990184 -0.334429204 0.072979107 0.018960828 -0.010014855 \n",
            "-0.035546474 -0.035546474 0.048807204 0.228184655 0.137479365 0.082194060 -0.133766308 -0.292224795 0.095152058 0.035858855 \n",
            "-0.034431644 -0.034431644 0.035893932 0.078085586 0.237618491 0.131813079 -0.090828486 -0.093487442 -0.269288480 0.114517450 \n",
            "-0.028771175 -0.028771175 0.036232222 0.061626874 0.083736122 0.228476942 -0.045845333 -0.047061358 -0.066815183 -0.245019972 \n",
            "----Moving Average coefficients----\n",
            "0.37474\n",
            "-0.59967\n",
            "-0.57637\n",
            "-0.64481\n",
            "-0.82333\n",
            "Lagged residuals \n",
            "1.00 0.67 0.75 1.24 -0.28 \n",
            "1.00 -0.42 0.67 0.75 1.24 \n",
            "1.00 -0.28 -0.42 0.67 0.75 \n",
            "1.00 1.24 -0.28 -0.42 0.67 \n",
            "1.00 0.75 1.24 -0.28 -0.42 \n",
            "1.00 0.67 0.75 1.24 -0.28 \n",
            "1.00 -0.42 0.67 0.75 1.24 \n",
            "1.00 -0.28 -0.42 0.67 0.75 \n",
            "1.00 1.24 -0.28 -0.42 0.67 \n",
            "1.00 0.75 1.24 -0.28 -0.42 \n",
            "\n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "0.00 0.36 0.36 -0.08 -0.20 -0.29 -0.42 0.77 0.49 0.50 \n",
            "0.00 0.00 0.36 0.36 -0.08 -0.20 -0.29 -0.42 0.77 0.49 \n",
            "0.00 0.00 0.00 0.36 0.36 -0.08 -0.20 -0.29 -0.42 0.77 \n",
            "0.00 0.00 0.00 0.00 0.36 0.36 -0.08 -0.20 -0.29 -0.42 \n",
            "\n",
            "Matrix multiplication result:\n",
            "16.00 4.00 3.41 2.91 2.42 \n",
            "4.00 3.62 1.23 0.96 0.52 \n",
            "3.41 1.23 3.27 0.93 0.67 \n",
            "2.91 0.96 0.93 3.02 0.69 \n",
            "2.42 0.52 0.67 0.69 2.78 \n",
            "\n",
            "Identity Matrix result:\n",
            "1.00 0.00 0.00 0.00 0.00 \n",
            "0.00 1.00 0.00 0.00 0.00 \n",
            "0.00 0.00 1.00 0.00 0.00 \n",
            "0.00 0.00 0.00 1.00 0.00 \n",
            "0.00 0.00 0.00 0.00 1.00 \n",
            "\n",
            "Inverse result:\n",
            "0.114410765 -0.083810806 -0.061486959 -0.051656779 -0.056262575 \n",
            "-0.083810806 0.393729329 -0.055407383 -0.032708786 0.021277681 \n",
            "-0.061486952 -0.055407375 0.408499092 -0.043570679 -0.024582040 \n",
            "-0.051656779 -0.032708786 -0.043570682 0.414230734 -0.040907584 \n",
            "-0.056262575 0.021277681 -0.024582040 -0.040907580 0.420990050 \n",
            "\n",
            "0.114410765 0.084456436 0.062480744 0.080840774 0.098009333 0.135299161 0.182822868 0.102048159 0.063904621 0.026407354 \n",
            "-0.083810806 0.056909677 0.037106849 -0.147568822 -0.163833171 -0.175869212 -0.229607999 0.249232233 0.074009441 0.050852012 \n",
            "-0.061486952 -0.081289776 0.064709477 0.073480427 -0.107995145 -0.134202451 -0.145035729 -0.259721994 0.252814233 0.087827533 \n",
            "-0.051656779 -0.063347034 -0.078919373 0.083499037 0.092026532 -0.081873588 -0.106542125 -0.169726491 -0.264988691 0.248360589 \n",
            "-0.056262575 -0.048657846 -0.057443567 -0.081412472 0.077245779 0.096434943 -0.084313847 -0.103637263 -0.169060305 -0.267625809 \n",
            "0.45616\n",
            "-0.26352\n",
            "-0.11238\n",
            "-0.16273\n",
            "-0.63675\n",
            "==15583== Profiling application: ./coeff_ma\n",
            "==15583== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   18.95%  242.17us        10  24.217us  3.7120us  122.72us  nodiag_normalize(float*, float*, int, int)\n",
            "                   17.68%  225.85us         1  225.85us  225.85us  225.85us  calres(float*, float*, float*, float*, int, int)\n",
            "                   14.65%  187.16us         1  187.16us  187.16us  187.16us  getTotalSum(unsigned long, float*, float*)\n",
            "                   13.69%  174.91us         2  87.454us  76.062us  98.846us  autoregressive(unsigned long, float*, float*, int)\n",
            "                   11.41%  145.79us         2  72.894us  70.815us  74.974us  transpose(float*, float*, int, unsigned long)\n",
            "                   10.34%  132.06us         6  22.010us  4.0960us  55.583us  matMulNaive(float*, float*, float*, unsigned long, unsigned long, unsigned long, unsigned long)\n",
            "                    6.01%  76.734us         1  76.734us  76.734us  76.734us  calculate_residuals(unsigned long, float*, float*, float*)\n",
            "                    2.52%  32.256us        10  3.2250us  2.9760us  3.3600us  gaussjordan(float*, float*, int, int)\n",
            "                    2.41%  30.848us        10  3.0840us  3.0080us  3.2960us  diag_normalize(float*, float*, int, int)\n",
            "                    1.98%  25.341us        10  2.5340us  2.4960us  2.5920us  set_zero(float*, float*, int, int)\n",
            "                    0.36%  4.5440us         1  4.5440us  4.5440us  4.5440us  calcuate_rate(unsigned long, float*, float*)\n",
            "      API calls:   96.37%  113.28ms        20  5.6640ms  3.1600us  113.18ms  cudaMallocManaged\n",
            "                    1.33%  1.5641ms        54  28.964us  3.0130us  231.11us  cudaDeviceSynchronize\n",
            "                    1.21%  1.4187ms        60  23.645us  4.5320us  181.43us  cudaMemPrefetchAsync\n",
            "                    0.70%  822.91us        54  15.239us  3.4100us  380.46us  cudaLaunchKernel\n",
            "                    0.15%  177.72us        18  9.8730us     449ns  42.500us  cudaFree\n",
            "                    0.12%  142.97us       114  1.2540us     105ns  60.180us  cuDeviceGetAttribute\n",
            "                    0.10%  119.25us        17  7.0140us  1.3970us  27.326us  cudaMemAdvise\n",
            "                    0.01%  11.735us         1  11.735us  11.735us  11.735us  cuDeviceGetName\n",
            "                    0.00%  4.8610us         1  4.8610us  4.8610us  4.8610us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.2590us        10     325ns     239ns     558ns  cudaGetLastError\n",
            "                    0.00%  1.9820us         1  1.9820us  1.9820us  1.9820us  cudaGetDevice\n",
            "                    0.00%  1.2500us         3     416ns     145ns     862ns  cuDeviceGetCount\n",
            "                    0.00%     894ns         2     447ns     191ns     703ns  cuDeviceGet\n",
            "                    0.00%     461ns         1     461ns     461ns     461ns  cuDeviceTotalMem\n",
            "                    0.00%     460ns         1     460ns     460ns     460ns  cuModuleGetLoadingMode\n",
            "                    0.00%     260ns         1     260ns     260ns     260ns  cuDeviceGetUuid\n",
            "\n",
            "==15583== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      16  9.0000KB  4.0000KB  40.000KB  144.0000KB  53.21400us  Host To Device\n",
            "      23  5.9121KB  4.0000KB  40.000KB  136.0000KB  46.39900us  Device To Host\n",
            "      12         -         -         -           -  905.1640us  Gpu page fault groups\n",
            "       2  4.0000KB  4.0000KB  4.0000KB  8.000000KB           -  Memory thrashes\n",
            "Total CPU Page faults: 4\n",
            "Total CPU thrashes: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}